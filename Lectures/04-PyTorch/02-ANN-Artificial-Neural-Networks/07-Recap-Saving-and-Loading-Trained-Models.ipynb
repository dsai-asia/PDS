{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Trained Models\n",
    "Refer back to this notebook as a refresher on saving and loading models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a trained model\n",
    "Save a trained model to a file in case you want to come back later and feed new data through it.\n",
    "\n",
    "\n",
    "To save a trained model called \"model\" to a file called \"MyModel.pt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MyModel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the model has been trained before saving (assumes the variables \"losses\" and \"epochs\" have been defined):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'MyModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a saved model (starting from scratch)\n",
    "We can load the trained weights and biases from a saved model. If we've just opened the notebook, we'll have to run standard imports and function definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform standard imports\n",
    "These will depend on the scope of the model, chosen displays, metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run the model definition\n",
    "We'll introduce the model shown below in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_sz=784, out_sz=10, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_sz,layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0],layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1],out_sz)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiate the model, load parameters\n",
    "First we instantiate the model, then we load the pre-trained weights & biases, and finally we set the model to \"eval\" mode to prevent any further backprops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MultilayerPerceptron()\n",
    "model2.load_state_dict(torch.load('MyModel.pt'));\n",
    "model2.eval() # be sure to run this step!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
