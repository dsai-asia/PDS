{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network Exercises - SOLUTIONS\n",
    "For these exercises we'll perform a binary classification on the Census Income dataset available from the <a href = 'http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a><br>\n",
    "The goal is to determine if an individual earns more than $50K based on a set of continuous and categorical variables.\n",
    "\n",
    "<div class=\"alert alert-danger\" style=\"margin: 10px\"><strong>IMPORTANT NOTE!</strong> Make sure you don't run the cells directly above the example output shown, <br>otherwise you will end up writing over the example output!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Income Dataset\n",
    "For this exercises we're using the Census Income dataset available from the <a href='http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a>.\n",
    "\n",
    "The full dataset has 48,842 entries. For this exercise we have reduced the number of records, fields and field entries, and have removed entries with null values. The file <strong>income.csv</strong> has\t30,000 entries\n",
    "\n",
    "Each entry contains the following information about an individual:\n",
    "* <strong>age</strong>: the age of an individual as an integer from 18 to 90 (continuous)\n",
    "* <strong>sex</strong>: Male or Female (categorical)\n",
    "* <strong>education</strong>: represents the highest level of education achieved by an individual (categorical)\n",
    "* <strong>education_num</strong>: represents education as an integer from 3 to 16 (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>3</td><td>5th-6th</td><td>8</td><td>12th</td><td>13</td><td>Bachelors</td></tr>\n",
    "<tr><td>4</td><td>7th-8th</td><td>9</td><td>HS-grad</td><td>14</td><td>Masters</td></tr>\n",
    "<tr><td>5</td><td>9th</td><td>10</td><td>Some-college</td><td>15</td><td>Prof-school</td></tr>\n",
    "<tr><td>6</td><td>10th</td><td>11</td><td>Assoc-voc</td><td>16</td><td>Doctorate</td></tr>\n",
    "<tr><td>7</td><td>11th</td><td>12</td><td>Assoc-acdm</td></tr>\n",
    "</table></div>\n",
    "* <strong>marital-status</strong>: marital status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Married</td><td>Divorced</td><td>Married-spouse-absent</td></tr>\n",
    "<tr><td>Separated</td><td>Widowed</td><td>Never-married</td></tr>\n",
    "</table></div>\n",
    "* <strong>workclass</strong>: a general term to represent the employment status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Local-gov</td><td>Private</td></tr>\n",
    "<tr><td>State-gov</td><td>Self-emp</td></tr>\n",
    "<tr><td>Federal-gov</td></tr>\n",
    "</table></div>\n",
    "* <strong>occupation</strong>: the general type of occupation of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Adm-clerical</td><td>Handlers-cleaners</td><td>Protective-serv</td></tr>\n",
    "<tr><td>Craft-repair</td><td>Machine-op-inspct</td><td>Sales</td></tr>\n",
    "<tr><td>Exec-managerial</td><td>Other-service</td><td>Tech-support</td></tr>\n",
    "<tr><td>Farming-fishing</td><td>Prof-specialty</td><td>Transport-moving</td></tr>\n",
    "</table></div>\n",
    "* <strong>hours-per-week</strong>: the hours an individual has reported to work per week as an integer from 20 to 90 (continuous)\n",
    "* <strong>income</strong>: whether or not an individual makes more than \\\\$50,000 annually (label)\n",
    "* <strong>label</strong>: income represented as an integer (0: <=\\\\$50K, 1: >\\\\$50K) (optional label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports\n",
    "Run the cell below to load the libraries needed for this exercise and the Census Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('../Data/income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Private</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>50</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>57</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>Female</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Private</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    education  education-num marital-status    workclass  \\\n",
       "0   27    Male      HS-grad              9  Never-married      Private   \n",
       "1   47    Male      Masters             14        Married    Local-gov   \n",
       "2   59    Male      HS-grad              9       Divorced     Self-emp   \n",
       "3   38  Female  Prof-school             15  Never-married  Federal-gov   \n",
       "4   64  Female         11th              7        Widowed      Private   \n",
       "\n",
       "        occupation  hours-per-week income  label  \n",
       "0     Craft-repair              40  <=50K      0  \n",
       "1  Exec-managerial              50   >50K      1  \n",
       "2   Prof-specialty              20  <=50K      0  \n",
       "3   Prof-specialty              57   >50K      1  \n",
       "4  Farming-fishing              40  <=50K      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21700\n",
       "1     8300\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Separate continuous, categorical and label column names\n",
    "You should find that there are 5 categorical columns, 2 continuous columns and 1 label.<br>\n",
    "In the case of <em>education</em> and <em>education-num</em> it doesn't matter which column you use. For the label column, be sure to use <em>label</em> and not <em>income</em>.<br>\n",
    "Assign the variable names \"cat_cols\", \"cont_cols\" and \"y_col\" to the lists of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS:\n",
    "print(f'cat_cols  has {len(cat_cols)} columns')\n",
    "print(f'cont_cols has {len(cont_cols)} columns')\n",
    "print(f'y_col     has {len(y_col)} column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols  has 5 columns\n",
      "cont_cols has 2 columns\n",
      "y_col     has 1 column\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "cat_cols = ['sex', 'education', 'marital-status', 'workclass', 'occupation']\n",
    "cont_cols = ['age', 'hours-per-week']\n",
    "y_col = ['label']\n",
    "\n",
    "print(f'cat_cols  has {len(cat_cols)} columns')  # 5\n",
    "print(f'cont_cols has {len(cont_cols)} columns') # 2\n",
    "print(f'y_col     has {len(y_col)} column')      # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert categorical columns to category dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Shuffle the dataset\n",
    "The <strong>income.csv</strong> dataset is already shuffled. However, if you would like to try different configurations after completing the exercises, this is where you would want to shuffle the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS OPTIONAL\n",
    "df = shuffle(df, random_state=101)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set the embedding sizes\n",
    "Create a variable \"cat_szs\" to hold the number of categories in each variable.<br>\n",
    "Then create a variable \"emb_szs\" to hold the list of (category size, embedding size) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (14, 7), (6, 3), (5, 3), (12, 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create an array of categorical values\n",
    "Create a NumPy array called \"cats\" that contains a stack of each categorical column <tt>.cat.codes.values</tt><br>\n",
    "Note: your output may contain different values. Ours came after performing the shuffle step shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10,  3,  2,  1],\n",
       "       [ 1, 11,  1,  1,  2],\n",
       "       [ 1, 10,  0,  3,  7],\n",
       "       [ 0, 12,  3,  0,  7],\n",
       "       [ 0,  1,  5,  2,  3]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "sx = df['sex'].cat.codes.values\n",
    "ed = df['education'].cat.codes.values\n",
    "ms = df['marital-status'].cat.codes.values\n",
    "wc = df['workclass'].cat.codes.values\n",
    "oc = df['occupation'].cat.codes.values\n",
    "\n",
    "cats = np.stack([sx,ed,ms,wc,oc], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convert \"cats\" to a tensor\n",
    "Convert the \"cats\" NumPy array to a tensor of dtype <tt>int64</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "cats = torch.tensor(cats, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create an array of continuous values\n",
    "Create a NumPy array called \"conts\" that contains a stack of each continuous column.<br>\n",
    "Note: your output may contain different values. Ours came after performing the shuffle step shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 40],\n",
       "       [47, 50],\n",
       "       [59, 20],\n",
       "       [38, 57],\n",
       "       [64, 40]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Convert \"conts\" to a tensor\n",
    "Convert the \"conts\" NumPy array to a tensor of dtype <tt>float32</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "conts.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a label tensor\n",
    "Create a tensor called \"y\" from the values in the label column. Be sure to flatten the tensor so that it can be passed into the CE Loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "y = torch.tensor(df[y_col].values).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create train and test sets from <tt>cats</tt>, <tt>conts</tt>, and <tt>y</tt>\n",
    "We use the entire batch of 30,000 records, but a smaller batch size will save time during training.<br>\n",
    "We used a test size of 5,000 records, but you can choose another fixed value or a percentage of the batch size.<br>\n",
    "Make sure that your test records remain separate from your training records, without overlap.<br>\n",
    "To make coding slices easier, we recommend assigning batch and test sizes to simple variables like \"b\" and \"t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "b = 30000 # suggested batch size\n",
    "t = 5000  # suggested test size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "b = 30000 # suggested batch size\n",
    "t = 5000  # suggested test size\n",
    "\n",
    "cat_train = cats[:b-t]\n",
    "cat_test  = cats[b-t:b]\n",
    "con_train = conts[:b-t]\n",
    "con_test  = conts[b-t:b]\n",
    "y_train   = y[:b-t]\n",
    "y_test    = y[b-t:b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model class\n",
    "Run the cell below to define the TabularModel model class we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        # Call the parent __init__\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set up the embedding, dropout, and batch normalization layer attributes\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Assign a variable to hold a list of layers\n",
    "        layerlist = []\n",
    "        \n",
    "        # Assign a variable to store the number of embedding and continuous layers\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        # Iterate through the passed-in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        \n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # Extract embedding values from the incoming categorical data\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        # Perform an initial dropout on the embeddings\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # Normalize the incoming continuous data\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        \n",
    "        # Set up model layers\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Set the random seed\n",
    "To obtain results that can be recreated, set a torch manual_seed (we used 33)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5e64e5e30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Create a TabularModel instance\n",
    "Create an instance called \"model\" with one hidden layer containing 50 neurons and a dropout layer p-value of 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(14, 7)\n",
       "    (2): Embedding(6, 3)\n",
       "    (3): Embedding(5, 3)\n",
       "    (4): Embedding(12, 6)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "model = TabularModel(emb_szs, conts.shape[1], 2, [50], p=0.4)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Define the loss and optimization functions\n",
    "Create a loss function called \"criterion\" using CrossEntropyLoss<br>\n",
    "Create an optimization function called \"optimizer\" using Adam, with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Run the cell below to train the model through 300 epochs. Remember, results may vary!<br>\n",
    "After completing the exercises, feel free to come back to this section and experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.65308946\n",
      "epoch:  26  loss: 0.54059124\n",
      "epoch:  51  loss: 0.46917316\n",
      "epoch:  76  loss: 0.41288978\n",
      "epoch: 101  loss: 0.37744597\n",
      "epoch: 126  loss: 0.35649022\n",
      "epoch: 151  loss: 0.34338138\n",
      "epoch: 176  loss: 0.33378774\n",
      "epoch: 201  loss: 0.32601979\n",
      "epoch: 226  loss: 0.32018784\n",
      "epoch: 251  loss: 0.31548899\n",
      "epoch: 276  loss: 0.30901730\n",
      "epoch: 300  loss: 0.30690485\n",
      "\n",
      "Duration: 170 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Plot the Cross Entropy Loss against epochs\n",
    "Results may vary. The shape of the plot is what matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Evaluate the test set\n",
    "With torch set to <tt>no_grad</tt>, pass <tt>cat_test</tt> and <tt>con_test</tt> through the trained model. Create a validation set called \"y_val\". Compare the output to <tt>y_test</tt> using the loss function defined above. Results may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.30774996\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Calculate the overall percent accuracy\n",
    "Using a for loop, compare the argmax values of the <tt>y_val</tt> validation set to the <tt>y_test</tt> set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4255 out of 5000 = 85.10% correct\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "rows = len(y_test)\n",
    "correct = 0\n",
    "\n",
    "# print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "\n",
    "for i in range(rows):\n",
    "    # print(f'{str(y_val[i]):26} {y_val[i].argmax().item():^7}{y_test[i]:^7}')\n",
    "\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Feed new data through the trained model\n",
    "See if you can write a function that allows a user to input their own values, and generates a prediction.<br>\n",
    "<strong>HINT</strong>:<br>There's no need to build a DataFrame. You can use inputs to populate column variables, convert them to embeddings with a context dictionary, and pass the embedded values directly into the tensor constructors:<br>\n",
    "<pre>mar = input(\"What is the person's marital status? \")\n",
    "mar_d = dict(Divorced=0, Married=1, Married-spouse-absent=2, Never-married=3, Separated=4, Widowed=5)\n",
    "mar = mar_d[mar]\n",
    "cats = torch.tensor([..., ..., mar, ..., ...], dtype=torch.int64).reshape(1,-1)</pre>\n",
    "Make sure that names are put in alphabetical order before assigning numbers.\n",
    "\n",
    "Also, be sure to run <tt>model.eval()</tt> before passing new date through. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the person's age? (18-90)  22\n",
      "What is the person's sex? (Male/Female) male\n",
      "What is the person's education level? (3-16) 12\n",
      "What is the person's marital status? married\n",
      "What is the person's workclass? private\n",
      "What is the person's occupation? sales\n",
      "How many hours/week are worked? (20-90)  40\n",
      "\n",
      "The predicted label is 0\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE\n",
    "def test_data(mdl): # pass in the name of the model\n",
    "    # INPUT NEW DATA\n",
    "    age = float(input(\"What is the person's age? (18-90)  \"))\n",
    "    sex = input(\"What is the person's sex? (Male/Female) \").capitalize()\n",
    "    edn = int(input(\"What is the person's education level? (3-16) \"))\n",
    "    mar = input(\"What is the person's marital status? \").capitalize()\n",
    "    wrk = input(\"What is the person's workclass? \").capitalize()\n",
    "    occ = input(\"What is the person's occupation? \").capitalize()\n",
    "    hrs = float(input(\"How many hours/week are worked? (20-90)  \"))\n",
    "\n",
    "    # PREPROCESS THE DATA\n",
    "    sex_d = {'Female':0, 'Male':1}\n",
    "    mar_d = {'Divorced':0, 'Married':1, 'Married-spouse-absent':2, 'Never-married':3, 'Separated':4, 'Widowed':5}\n",
    "    wrk_d = {'Federal-gov':0, 'Local-gov':1, 'Private':2, 'Self-emp':3, 'State-gov':4}\n",
    "    occ_d = {'Adm-clerical':0, 'Craft-repair':1, 'Exec-managerial':2, 'Farming-fishing':3, 'Handlers-cleaners':4,\n",
    "            'Machine-op-inspct':5, 'Other-service':6, 'Prof-specialty':7, 'Protective-serv':8, 'Sales':9, \n",
    "            'Tech-support':10, 'Transport-moving':11}\n",
    "\n",
    "    sex = sex_d[sex]\n",
    "    mar = mar_d[mar]\n",
    "    wrk = wrk_d[wrk]\n",
    "    occ = occ_d[occ]\n",
    "\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cats = torch.tensor([sex,edn,mar,wrk,occ], dtype=torch.int64).reshape(1,-1)\n",
    "    conts = torch.tensor([age,hrs], dtype=torch.float).reshape(1,-1)\n",
    "    \n",
    "    # SET MODEL TO EVAL (in case this hasn't been done)\n",
    "    mdl.eval()\n",
    "\n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(cats, conts).argmax().item()\n",
    "\n",
    "    print(f'\\nThe predicted label is {z}')\n",
    "    \n",
    "test_data(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
