{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Code Along with CNN\n",
    "Now that we've seen the results of an artificial neural network model on the <a href='https://en.wikipedia.org/wiki/MNIST_database'>MNIST dataset</a>, let's work the same data with a <a href='https://en.wikipedia.org/wiki/Convolutional_neural_network'>Convolutional Neural Network</a> (CNN).\n",
    "Make sure to watch the theory lectures! You'll want to be comfortable with:\n",
    "* convolutional layers\n",
    "* filters/kernels\n",
    "* pooling\n",
    "* depth, stride and zero-padding\n",
    "\n",
    "Note that in this exercise there is no need to flatten the MNIST data, as a CNN expects 2-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset\n",
    "PyTorch makes the MNIST train and test datasets available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. The first time they're called, the datasets will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download.\n",
    "\n",
    "Refer to the previous section for explanations of transformations, batch sizes and <a href='https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader'><tt><strong>DataLoader</strong></tt></a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # Pytorch transformation to tensor\n",
    "\n",
    "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loaders\n",
    "When working with images, we want relatively small batches; a batch size of 4 is not uncommon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional model\n",
    "In the previous section we used only fully connected layers, with an input layer of 784 (our flattened 28x28 images), hidden layers of 120 and 84 neurons, and an output size representing 10 possible digits.\n",
    "\n",
    "This time we'll employ two convolutional layers and two pooling layers before feeding data through fully connected hidden layers to our output. The model follows CONV/RELU/POOL/CONV/RELU/POOL/FC/RELU/FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take.</strong><br>\n",
    "\n",
    "1. Extend the base Module class:\n",
    "   \n",
    "<tt><font color=black>class ConvolutionalNetwork(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the convolutional layers with <a href='https://pytorch.org/docs/stable/nn.html#conv2d'><tt><strong>torch.nn.Conv2d()</strong></tt></a><br><br>The first layer has one input channel (the grayscale color channel). We'll assign 6 output channels for feature extraction. We'll set our kernel size to 3 to make a 3x3 filter, and set the step size to 1.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv1 = nn.Conv2d(1, 6, 3, 1)</font></tt><br>\n",
    "The second layer will take our 6 input channels and deliver 16 output channels.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv2 = nn.Conv2d(6, 16, 3, 1)</font></tt><br><br>\n",
    "\n",
    "3. Set up the fully connected layers with <a href='https://pytorch.org/docs/stable/nn.html#linear'><tt><strong>torch.nn.Linear()</strong></tt></a>.<br><br>The input size of (5x5x16) is determined by the effect of our kernels on the input image size. A 3x3 filter applied to a 28x28 image leaves a 1-pixel edge on all four sides. In one layer the size changes from 28x28 to 26x26. We could address this with zero-padding, but since an MNIST image is mostly black at the edges, we should be safe ignoring these pixels. We'll apply the kernel twice, and apply pooling layers twice, so our resulting output will be \n",
    "$\\;(((28-2)/2)-2)/2 = 5.5\\;$ which rounds down to 5 pixels per side.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc1 = nn.Linear(5\\*5\\*16, 120)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc2 = nn.Linear(120, 84)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc3 = nn.Linear(84, 10)</font></tt><br>\n",
    "See below for a more detailed look at this step.<br><br>\n",
    "\n",
    "4. Define the forward method.<br><br>Activations can be applied to the convolutions in one line using <a href='https://pytorch.org/docs/stable/nn.html#id27'><tt><strong>F.relu()</strong></tt></a> and pooling is done using <a href='https://pytorch.org/docs/stable/nn.html#maxpool2d'><tt><strong>F.max_pool2d()</strong></tt></a><br>\n",
    "<tt><font color=black>def forward(self, X):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv2(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "</font></tt>Flatten the data for the fully connected layers:<br><tt><font color=black>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = X.view(-1, 5\\*5\\*16)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.fc1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = self.fc2(X)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return F.log_softmax(X, dim=1)</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the convolutional layers</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the first MNIST record\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break\n",
    "    \n",
    "X_train.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank-4 tensor to be passed into the model\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Run the first pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data\n",
    "x = x.view(-1, 5*5*16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the convolution output is passed into the fully connected layers.</strong></div>\n",
    "\n",
    "Now let's run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the bias terms for each layer, the total number of parameters being trained is:<br>\n",
    "\n",
    "$\\quad\\begin{split}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times120)+120+(120\\times84)+84+(84\\times10)+10 &=\\\\\n",
    "54+6+864+16+48000+120+10080+84+840+10 &= 60,074\\end{split}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 48000\n",
      "   120\n",
      " 10080\n",
      "    84\n",
      "   840\n",
      "    10\n",
      "______\n",
      " 60074\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
      "          [ 0.3062, -0.0730,  0.0673],\n",
      "          [-0.1623,  0.1958,  0.2938]]],\n",
      "\n",
      "\n",
      "        [[[-0.2445,  0.2897,  0.0624],\n",
      "          [ 0.2463,  0.0451,  0.1607],\n",
      "          [-0.0471,  0.2570,  0.0493]]],\n",
      "\n",
      "\n",
      "        [[[-0.1556,  0.0850, -0.1536],\n",
      "          [-0.0391, -0.1354,  0.2211],\n",
      "          [-0.2631, -0.1537, -0.0941]]],\n",
      "\n",
      "\n",
      "        [[[-0.2004,  0.0315, -0.3292],\n",
      "          [ 0.3010, -0.2832,  0.2573],\n",
      "          [ 0.0555, -0.1082,  0.2060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0520,  0.2693,  0.0364],\n",
      "          [-0.1051,  0.0896, -0.0904],\n",
      "          [ 0.1403,  0.2976,  0.1927]]],\n",
      "\n",
      "\n",
      "        [[[-0.1457,  0.1924,  0.0596],\n",
      "          [ 0.1693, -0.2032, -0.3300],\n",
      "          [-0.1288, -0.2557,  0.2735]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0960,  0.1381,  0.1054, -0.0058,  0.2609, -0.2368],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0086, -0.0929,  0.0420],\n",
      "          [-0.0469,  0.0417, -0.0284],\n",
      "          [ 0.1129, -0.0807, -0.0812]],\n",
      "\n",
      "         [[-0.0812,  0.1224,  0.0453],\n",
      "          [ 0.1309, -0.1123, -0.1350],\n",
      "          [-0.1065, -0.0915,  0.0551]],\n",
      "\n",
      "         [[ 0.0487,  0.1131, -0.0703],\n",
      "          [-0.0928,  0.0722, -0.0550],\n",
      "          [ 0.0826, -0.0323,  0.0778]],\n",
      "\n",
      "         [[-0.1057, -0.0687,  0.0415],\n",
      "          [ 0.0288, -0.0347,  0.0811],\n",
      "          [ 0.0925, -0.0987, -0.0727]],\n",
      "\n",
      "         [[ 0.1246, -0.0459, -0.0482],\n",
      "          [-0.1317, -0.0779,  0.0340],\n",
      "          [-0.0180, -0.0988,  0.0032]],\n",
      "\n",
      "         [[-0.0930, -0.1155, -0.0749],\n",
      "          [-0.1191, -0.0866,  0.1360],\n",
      "          [ 0.0257,  0.0419, -0.1269]]],\n",
      "\n",
      "\n",
      "        [[[-0.0894, -0.0453,  0.0213],\n",
      "          [-0.1197, -0.0586, -0.0815],\n",
      "          [ 0.0004, -0.0506, -0.0094]],\n",
      "\n",
      "         [[-0.0922, -0.0934, -0.0794],\n",
      "          [-0.0466, -0.1074,  0.1141],\n",
      "          [-0.0270,  0.1171,  0.0424]],\n",
      "\n",
      "         [[-0.1152,  0.0942, -0.0374],\n",
      "          [-0.0522, -0.1130, -0.1353],\n",
      "          [ 0.0389, -0.0297,  0.0530]],\n",
      "\n",
      "         [[-0.1117,  0.1010, -0.0999],\n",
      "          [-0.0235,  0.0284,  0.0703],\n",
      "          [ 0.1099,  0.1240, -0.1079]],\n",
      "\n",
      "         [[ 0.0342, -0.0585, -0.0149],\n",
      "          [-0.1019,  0.1240, -0.0999],\n",
      "          [ 0.0727,  0.0478,  0.0442]],\n",
      "\n",
      "         [[-0.0736,  0.1237,  0.0299],\n",
      "          [ 0.0175, -0.1199,  0.0571],\n",
      "          [-0.0204, -0.0623,  0.1169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303, -0.0753, -0.0689],\n",
      "          [-0.0065,  0.0760, -0.0348],\n",
      "          [-0.0776, -0.0466, -0.1017]],\n",
      "\n",
      "         [[ 0.0485,  0.1053, -0.1281],\n",
      "          [ 0.0316,  0.0703,  0.0247],\n",
      "          [-0.0485,  0.0710,  0.0715]],\n",
      "\n",
      "         [[ 0.0509, -0.0239, -0.0360],\n",
      "          [ 0.0146, -0.0240, -0.0406],\n",
      "          [ 0.0870,  0.1169, -0.0135]],\n",
      "\n",
      "         [[-0.0305,  0.0020, -0.0081],\n",
      "          [ 0.0327,  0.0381, -0.1236],\n",
      "          [-0.0502,  0.1146,  0.0530]],\n",
      "\n",
      "         [[-0.0068, -0.0820, -0.0833],\n",
      "          [-0.1219, -0.0444,  0.0460],\n",
      "          [ 0.0868,  0.0628, -0.1203]],\n",
      "\n",
      "         [[-0.0818, -0.0215,  0.1316],\n",
      "          [ 0.0197, -0.0352,  0.0563],\n",
      "          [-0.0518, -0.0881,  0.0993]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619, -0.0273, -0.1354],\n",
      "          [ 0.0911,  0.1031,  0.0496],\n",
      "          [-0.0949, -0.1343, -0.1105]],\n",
      "\n",
      "         [[ 0.1015,  0.0653,  0.1145],\n",
      "          [ 0.0713,  0.0344, -0.0013],\n",
      "          [-0.1035, -0.1166, -0.1273]],\n",
      "\n",
      "         [[ 0.0557, -0.0668, -0.0274],\n",
      "          [-0.0783, -0.0248, -0.0958],\n",
      "          [-0.0889,  0.0451, -0.0404]],\n",
      "\n",
      "         [[ 0.0840, -0.0437, -0.0998],\n",
      "          [-0.0240, -0.0660, -0.0416],\n",
      "          [-0.1296,  0.0761, -0.0947]],\n",
      "\n",
      "         [[ 0.0684,  0.0618,  0.0972],\n",
      "          [-0.1044,  0.0979, -0.0643],\n",
      "          [ 0.0505,  0.1278, -0.0192]],\n",
      "\n",
      "         [[-0.0011, -0.0313, -0.1136],\n",
      "          [ 0.0653, -0.1351,  0.0845],\n",
      "          [ 0.1018,  0.1287, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.1118,  0.0306,  0.0752],\n",
      "          [-0.1354, -0.0309, -0.0816],\n",
      "          [-0.0119, -0.0670, -0.0556]],\n",
      "\n",
      "         [[-0.0432, -0.1293,  0.1117],\n",
      "          [ 0.1141, -0.0213, -0.0155],\n",
      "          [-0.0555, -0.1229, -0.1324]],\n",
      "\n",
      "         [[ 0.0506, -0.0747, -0.0875],\n",
      "          [-0.0106, -0.0453, -0.0440],\n",
      "          [ 0.0044, -0.0289, -0.0469]],\n",
      "\n",
      "         [[-0.0652, -0.1107,  0.1141],\n",
      "          [-0.0545,  0.0361, -0.0472],\n",
      "          [ 0.0111,  0.1269,  0.0627]],\n",
      "\n",
      "         [[-0.1179,  0.0540,  0.1292],\n",
      "          [ 0.0358,  0.0912,  0.1342],\n",
      "          [-0.0209,  0.0282, -0.0946]],\n",
      "\n",
      "         [[-0.0280,  0.1008,  0.0698],\n",
      "          [-0.0861, -0.1091, -0.0930],\n",
      "          [-0.1343, -0.1050, -0.0337]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0918,  0.0228, -0.1035],\n",
      "          [-0.1092,  0.0677, -0.1012],\n",
      "          [-0.0168,  0.0653, -0.0630]],\n",
      "\n",
      "         [[-0.0148, -0.0118, -0.0322],\n",
      "          [-0.0690, -0.1213, -0.1100],\n",
      "          [-0.0729,  0.1314, -0.0657]],\n",
      "\n",
      "         [[-0.0914,  0.0330,  0.0375],\n",
      "          [ 0.0746,  0.1034,  0.0758],\n",
      "          [-0.1349,  0.0121,  0.0824]],\n",
      "\n",
      "         [[-0.0126, -0.0802,  0.1297],\n",
      "          [-0.0509, -0.0775, -0.1227],\n",
      "          [ 0.0061,  0.0603,  0.0301]],\n",
      "\n",
      "         [[ 0.0269, -0.1032, -0.1271],\n",
      "          [ 0.0024,  0.1241,  0.0785],\n",
      "          [-0.0792, -0.0177, -0.1003]],\n",
      "\n",
      "         [[-0.0656,  0.0246,  0.0741],\n",
      "          [ 0.1127, -0.1249,  0.0910],\n",
      "          [-0.0960,  0.0510,  0.1152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019,  0.1238, -0.1159],\n",
      "          [-0.0520,  0.0794, -0.0296],\n",
      "          [-0.0279, -0.0567,  0.0938]],\n",
      "\n",
      "         [[ 0.0667,  0.0436, -0.0765],\n",
      "          [-0.1105,  0.0147,  0.0403],\n",
      "          [-0.0628, -0.0381,  0.0919]],\n",
      "\n",
      "         [[ 0.0108,  0.0061, -0.0335],\n",
      "          [-0.1232, -0.1280, -0.0650],\n",
      "          [-0.0692,  0.0424, -0.0396]],\n",
      "\n",
      "         [[-0.0532,  0.1297,  0.0474],\n",
      "          [ 0.0970, -0.0659, -0.0556],\n",
      "          [ 0.0500, -0.0907, -0.0890]],\n",
      "\n",
      "         [[-0.0066, -0.0498, -0.1020],\n",
      "          [ 0.0807,  0.1094,  0.0221],\n",
      "          [-0.0237, -0.1260, -0.0496]],\n",
      "\n",
      "         [[ 0.0346,  0.0642, -0.0172],\n",
      "          [-0.0538,  0.0758, -0.1084],\n",
      "          [ 0.0860, -0.0528,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[-0.0269,  0.0165, -0.0411],\n",
      "          [ 0.0989, -0.0035,  0.1062],\n",
      "          [ 0.1308, -0.0663, -0.0993]],\n",
      "\n",
      "         [[ 0.1092,  0.1066, -0.1039],\n",
      "          [-0.0105, -0.1342, -0.1114],\n",
      "          [ 0.0263,  0.0362,  0.0288]],\n",
      "\n",
      "         [[-0.0370,  0.1255,  0.0195],\n",
      "          [-0.0803, -0.0077,  0.0327],\n",
      "          [ 0.0477, -0.0962,  0.0510]],\n",
      "\n",
      "         [[-0.0695, -0.1131, -0.0743],\n",
      "          [ 0.1312,  0.1163,  0.1219],\n",
      "          [ 0.0799,  0.1028, -0.0182]],\n",
      "\n",
      "         [[-0.0749,  0.0680, -0.0705],\n",
      "          [-0.0918, -0.0435,  0.0286],\n",
      "          [ 0.0701, -0.0529, -0.0801]],\n",
      "\n",
      "         [[ 0.0184, -0.0802, -0.0886],\n",
      "          [ 0.0709, -0.0229,  0.1244],\n",
      "          [ 0.1324,  0.0407,  0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0021, -0.0099],\n",
      "          [ 0.0019,  0.0508,  0.1265],\n",
      "          [-0.0353, -0.0575, -0.0330]],\n",
      "\n",
      "         [[-0.0657,  0.0231,  0.1016],\n",
      "          [ 0.1064,  0.0625, -0.1001],\n",
      "          [-0.0730, -0.0299, -0.0251]],\n",
      "\n",
      "         [[ 0.0112, -0.1249,  0.0424],\n",
      "          [-0.1038, -0.0861, -0.1131],\n",
      "          [ 0.1186, -0.1289,  0.1027]],\n",
      "\n",
      "         [[-0.0046, -0.0158,  0.0851],\n",
      "          [-0.0126,  0.0853,  0.0984],\n",
      "          [-0.1181,  0.0524,  0.0257]],\n",
      "\n",
      "         [[ 0.0293,  0.0199,  0.0372],\n",
      "          [-0.0655, -0.0174,  0.1293],\n",
      "          [ 0.0914, -0.0051, -0.1280]],\n",
      "\n",
      "         [[ 0.0060, -0.0927,  0.1107],\n",
      "          [-0.0826, -0.0098, -0.0302],\n",
      "          [ 0.0242,  0.1281,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0788,  0.1056,  0.1099],\n",
      "          [-0.0470, -0.0304,  0.0656],\n",
      "          [-0.0371,  0.0637, -0.0297]],\n",
      "\n",
      "         [[-0.0923,  0.0554,  0.0209],\n",
      "          [ 0.0607,  0.1352,  0.0929],\n",
      "          [ 0.1290,  0.0073, -0.1171]],\n",
      "\n",
      "         [[-0.0955, -0.0845, -0.1199],\n",
      "          [-0.0682, -0.1253, -0.1256],\n",
      "          [-0.0813, -0.1342, -0.0835]],\n",
      "\n",
      "         [[ 0.0519,  0.1135, -0.0405],\n",
      "          [-0.0396,  0.0727, -0.0671],\n",
      "          [-0.0643,  0.0838, -0.1186]],\n",
      "\n",
      "         [[ 0.0166,  0.1202,  0.0233],\n",
      "          [ 0.0370, -0.0793, -0.0019],\n",
      "          [ 0.0075,  0.0334,  0.0529]],\n",
      "\n",
      "         [[ 0.1182, -0.1039,  0.0041],\n",
      "          [-0.0680, -0.1077, -0.0109],\n",
      "          [-0.1198,  0.0950,  0.0158]]],\n",
      "\n",
      "\n",
      "        [[[-0.0733,  0.0711, -0.1288],\n",
      "          [-0.0526, -0.0265, -0.1156],\n",
      "          [-0.0865, -0.0222,  0.1033]],\n",
      "\n",
      "         [[ 0.1314,  0.0866, -0.0813],\n",
      "          [-0.0890,  0.1188,  0.0481],\n",
      "          [ 0.0036,  0.0184, -0.1094]],\n",
      "\n",
      "         [[-0.0454,  0.1310, -0.0336],\n",
      "          [-0.0068, -0.1130, -0.0761],\n",
      "          [-0.0028, -0.0845, -0.0169]],\n",
      "\n",
      "         [[ 0.0554, -0.1331,  0.0404],\n",
      "          [-0.0900, -0.0664,  0.0522],\n",
      "          [ 0.1082, -0.0372, -0.0559]],\n",
      "\n",
      "         [[-0.1231, -0.0702, -0.1192],\n",
      "          [-0.0311,  0.0278, -0.1275],\n",
      "          [ 0.1188,  0.0854, -0.1332]],\n",
      "\n",
      "         [[-0.0650,  0.0444, -0.0280],\n",
      "          [-0.0148, -0.0614,  0.1093],\n",
      "          [-0.0761,  0.1129,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274,  0.1062, -0.0224],\n",
      "          [-0.0775, -0.0220,  0.1104],\n",
      "          [-0.1010,  0.0309, -0.1337]],\n",
      "\n",
      "         [[ 0.0713,  0.0503,  0.0058],\n",
      "          [ 0.0584,  0.0002,  0.0753],\n",
      "          [-0.1077, -0.0200,  0.0604]],\n",
      "\n",
      "         [[ 0.1355,  0.0693, -0.0990],\n",
      "          [ 0.1047, -0.0303, -0.0291],\n",
      "          [-0.1237, -0.0214,  0.0963]],\n",
      "\n",
      "         [[ 0.0190, -0.0793,  0.0419],\n",
      "          [-0.0436,  0.1242, -0.1181],\n",
      "          [-0.0430, -0.1314, -0.0536]],\n",
      "\n",
      "         [[ 0.0429,  0.1310,  0.0229],\n",
      "          [ 0.1334,  0.0266,  0.0786],\n",
      "          [ 0.1091,  0.1138, -0.0762]],\n",
      "\n",
      "         [[ 0.1251,  0.0824, -0.0636],\n",
      "          [-0.0649, -0.1141,  0.0342],\n",
      "          [-0.1103,  0.0575,  0.0430]]],\n",
      "\n",
      "\n",
      "        [[[-0.1182,  0.0371, -0.0111],\n",
      "          [ 0.0622,  0.0781, -0.1353],\n",
      "          [ 0.1248,  0.1141,  0.0541]],\n",
      "\n",
      "         [[-0.1244, -0.0486, -0.0394],\n",
      "          [-0.0350,  0.0767,  0.0495],\n",
      "          [ 0.1078, -0.0510,  0.0458]],\n",
      "\n",
      "         [[ 0.0484, -0.1133, -0.1320],\n",
      "          [-0.0706,  0.0932, -0.1281],\n",
      "          [-0.1185,  0.0762,  0.0734]],\n",
      "\n",
      "         [[ 0.1119, -0.1027, -0.0996],\n",
      "          [ 0.0698,  0.1183,  0.0814],\n",
      "          [ 0.0213,  0.0448,  0.1292]],\n",
      "\n",
      "         [[-0.0878, -0.0618,  0.0952],\n",
      "          [-0.0931, -0.0750,  0.0993],\n",
      "          [ 0.0429,  0.0440, -0.0577]],\n",
      "\n",
      "         [[-0.0019,  0.1245, -0.0817],\n",
      "          [ 0.0011,  0.0647, -0.0939],\n",
      "          [ 0.1322, -0.0680, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.0368, -0.0887, -0.1335],\n",
      "          [ 0.0767,  0.0362, -0.1275],\n",
      "          [-0.0876,  0.1345,  0.0520]],\n",
      "\n",
      "         [[ 0.0546, -0.0814, -0.0597],\n",
      "          [-0.0205, -0.0249, -0.0933],\n",
      "          [ 0.0112,  0.0135, -0.0172]],\n",
      "\n",
      "         [[ 0.0189, -0.0539,  0.0354],\n",
      "          [ 0.0513, -0.0717, -0.1349],\n",
      "          [ 0.0712,  0.0325, -0.0692]],\n",
      "\n",
      "         [[ 0.1311, -0.0615,  0.0920],\n",
      "          [ 0.0690, -0.1141,  0.0878],\n",
      "          [-0.1251, -0.0754, -0.0227]],\n",
      "\n",
      "         [[-0.0917,  0.1329, -0.0273],\n",
      "          [ 0.0541, -0.1215,  0.0783],\n",
      "          [-0.0423, -0.1035,  0.0199]],\n",
      "\n",
      "         [[ 0.0659,  0.1178, -0.0831],\n",
      "          [-0.0670,  0.0262,  0.0369],\n",
      "          [ 0.0523,  0.0747, -0.0309]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0756,  0.1003, -0.0355],\n",
      "          [ 0.0968,  0.0665,  0.1200],\n",
      "          [-0.0773, -0.0672, -0.0393]],\n",
      "\n",
      "         [[ 0.0069,  0.0817, -0.0777],\n",
      "          [ 0.0681, -0.0488,  0.0822],\n",
      "          [-0.0065, -0.1192, -0.0749]],\n",
      "\n",
      "         [[-0.0985,  0.0675, -0.0913],\n",
      "          [-0.0113,  0.0294, -0.0746],\n",
      "          [ 0.0393, -0.1329, -0.0974]],\n",
      "\n",
      "         [[-0.1233, -0.0412, -0.0496],\n",
      "          [ 0.0195, -0.0252,  0.0640],\n",
      "          [ 0.1248,  0.0488, -0.0536]],\n",
      "\n",
      "         [[-0.1274,  0.0493, -0.0674],\n",
      "          [ 0.0692,  0.0910,  0.0525],\n",
      "          [ 0.1277,  0.1293,  0.0288]],\n",
      "\n",
      "         [[-0.0992,  0.1216, -0.0646],\n",
      "          [-0.0643,  0.1139,  0.1054],\n",
      "          [ 0.0411,  0.0085, -0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141,  0.1305,  0.0347],\n",
      "          [ 0.0117, -0.0283, -0.0475],\n",
      "          [ 0.0811,  0.0084,  0.0885]],\n",
      "\n",
      "         [[-0.0241,  0.0595,  0.0562],\n",
      "          [ 0.0217,  0.0855,  0.0853],\n",
      "          [ 0.1261,  0.1046, -0.0348]],\n",
      "\n",
      "         [[-0.1152,  0.0249, -0.0012],\n",
      "          [-0.0355, -0.0228,  0.0064],\n",
      "          [ 0.0993,  0.0424, -0.0483]],\n",
      "\n",
      "         [[-0.0560, -0.0337, -0.0526],\n",
      "          [ 0.1224,  0.0721,  0.1229],\n",
      "          [ 0.0004,  0.0274,  0.0472]],\n",
      "\n",
      "         [[-0.1288,  0.0122, -0.0091],\n",
      "          [-0.0763, -0.1056,  0.1205],\n",
      "          [ 0.1106,  0.0631,  0.1299]],\n",
      "\n",
      "         [[-0.0552, -0.0235,  0.0515],\n",
      "          [-0.0225, -0.0267, -0.1125],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [ 0.0366, -0.0822,  0.0049]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1327, -0.0419, -0.0429,  0.0821, -0.0500, -0.0117,  0.1271, -0.0558,\n",
      "        -0.0974, -0.0762, -0.0377, -0.0646, -0.0706,  0.0550,  0.0231, -0.0436],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.8846e-02, -1.5743e-02, -2.1102e-02,  ..., -7.6693e-05,\n",
      "          4.8436e-02, -1.9859e-02],\n",
      "        [-1.1636e-02, -2.5271e-02,  7.1948e-03,  ..., -1.7114e-02,\n",
      "         -2.9444e-02,  3.3103e-02],\n",
      "        [ 6.7186e-03,  2.0927e-02, -1.8936e-02,  ..., -4.6726e-02,\n",
      "          3.3182e-03, -1.7761e-02],\n",
      "        ...,\n",
      "        [-4.3866e-02,  3.7438e-02, -4.2277e-02,  ...,  4.5558e-02,\n",
      "          2.3612e-02, -4.4892e-02],\n",
      "        [ 1.6117e-02,  1.6008e-02,  2.6415e-02,  ..., -3.6400e-02,\n",
      "          1.4238e-02,  3.9001e-02],\n",
      "        [-1.7557e-02, -2.1580e-02,  4.0183e-02,  ...,  5.0929e-03,\n",
      "          4.3303e-02, -4.1396e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0400, -0.0132, -0.0299, -0.0310,  0.0312,  0.0441,  0.0343, -0.0473,\n",
      "        -0.0008,  0.0072,  0.0363, -0.0249, -0.0220, -0.0055, -0.0091,  0.0066,\n",
      "        -0.0191, -0.0118, -0.0330,  0.0443, -0.0144, -0.0258, -0.0401, -0.0316,\n",
      "         0.0284,  0.0334,  0.0075, -0.0444, -0.0477, -0.0182, -0.0170, -0.0190,\n",
      "        -0.0163, -0.0279, -0.0349,  0.0035, -0.0400, -0.0317, -0.0016,  0.0015,\n",
      "         0.0436, -0.0034,  0.0314, -0.0055,  0.0237, -0.0089,  0.0256,  0.0277,\n",
      "        -0.0481,  0.0012,  0.0010,  0.0096, -0.0472, -0.0495, -0.0400, -0.0047,\n",
      "         0.0345, -0.0277, -0.0216, -0.0290,  0.0261,  0.0368,  0.0033,  0.0269,\n",
      "         0.0461, -0.0069, -0.0212, -0.0286,  0.0359,  0.0303, -0.0336,  0.0286,\n",
      "         0.0226,  0.0231,  0.0172, -0.0077,  0.0228, -0.0317, -0.0057,  0.0200,\n",
      "         0.0196, -0.0247, -0.0427,  0.0248, -0.0250,  0.0274, -0.0473, -0.0432,\n",
      "         0.0465,  0.0449, -0.0165,  0.0297,  0.0328, -0.0133,  0.0391,  0.0355,\n",
      "         0.0485, -0.0063, -0.0442, -0.0260, -0.0080, -0.0207,  0.0316,  0.0417,\n",
      "         0.0384,  0.0112, -0.0234, -0.0303, -0.0059, -0.0286,  0.0399, -0.0384,\n",
      "        -0.0390, -0.0290, -0.0329, -0.0307,  0.0183, -0.0207, -0.0320,  0.0365],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0371,  0.0817,  0.0687,  ..., -0.0570,  0.0406, -0.0083],\n",
      "        [ 0.0591, -0.0907, -0.0863,  ..., -0.0754,  0.0787, -0.0542],\n",
      "        [-0.0385, -0.0518,  0.0064,  ...,  0.0870,  0.0634, -0.0167],\n",
      "        ...,\n",
      "        [-0.0752,  0.0148, -0.0138,  ...,  0.0169,  0.0578, -0.0175],\n",
      "        [ 0.0579, -0.0846, -0.0538,  ..., -0.0163,  0.0133,  0.0372],\n",
      "        [-0.0691, -0.0808,  0.0382,  ..., -0.0006, -0.0693, -0.0764]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0058,  0.0849,  0.0859, -0.0189,  0.0273, -0.0852, -0.0591,  0.0678,\n",
      "         0.0148,  0.0224,  0.0103, -0.0367,  0.0740,  0.0870,  0.0377,  0.0854,\n",
      "         0.0274,  0.0690, -0.0584,  0.0318, -0.0649, -0.0117, -0.0593,  0.0311,\n",
      "        -0.0852, -0.0268, -0.0367,  0.0592, -0.0653, -0.0452,  0.0764,  0.0387,\n",
      "         0.0709,  0.0839, -0.0556,  0.0249, -0.0682, -0.0311, -0.0149, -0.0454,\n",
      "         0.0190,  0.0133,  0.0189,  0.0501, -0.0112,  0.0732, -0.0066,  0.0625,\n",
      "         0.0711,  0.0843, -0.0440, -0.0322, -0.0702, -0.0380,  0.0840, -0.0104,\n",
      "        -0.0479, -0.0699, -0.0730, -0.0506,  0.0307, -0.0485, -0.0318, -0.0764,\n",
      "        -0.0815, -0.0529, -0.0844, -0.0059, -0.0318, -0.0430, -0.0552,  0.0333,\n",
      "         0.0385, -0.0173,  0.0355,  0.0825, -0.0293, -0.0550,  0.0566, -0.0207,\n",
      "        -0.0371,  0.0593,  0.0267, -0.0664], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0248,  0.0496,  0.1048, -0.0526,  0.0552, -0.0156,  0.0163, -0.1028,\n",
      "         -0.0987,  0.0589,  0.0010,  0.0489, -0.0655,  0.0836, -0.0392, -0.0669,\n",
      "          0.0943, -0.0640, -0.0646, -0.0934,  0.0483, -0.0124, -0.0031,  0.0337,\n",
      "         -0.0306,  0.0181, -0.0586, -0.0257,  0.0614,  0.0329,  0.0728,  0.1024,\n",
      "          0.0769, -0.0391, -0.0918, -0.0467, -0.0079,  0.1040,  0.0128, -0.0154,\n",
      "          0.0767,  0.0438,  0.0905,  0.0158, -0.0073,  0.0525, -0.0067, -0.0647,\n",
      "         -0.0306, -0.0497, -0.0082,  0.0735,  0.0210, -0.0641, -0.0340, -0.0675,\n",
      "         -0.0203, -0.0563,  0.0341, -0.0174, -0.0606,  0.0495,  0.0197,  0.0262,\n",
      "          0.0665,  0.0555, -0.0718,  0.0611, -0.0739, -0.0849,  0.1066, -0.0612,\n",
      "          0.0044,  0.0641, -0.0631, -0.0488,  0.0129, -0.0111,  0.0599,  0.0168,\n",
      "         -0.0014,  0.0162,  0.1045, -0.0783],\n",
      "        [ 0.0882,  0.0137,  0.0816,  0.0278, -0.0595,  0.1075,  0.0605, -0.0945,\n",
      "          0.0949,  0.0850,  0.0864,  0.0311,  0.0391, -0.0184,  0.0773, -0.0719,\n",
      "          0.0261,  0.0701, -0.0290,  0.0690,  0.0600,  0.0104,  0.0042, -0.0508,\n",
      "         -0.0048, -0.1056,  0.0545,  0.0531,  0.0336, -0.0486, -0.0944, -0.0654,\n",
      "          0.0298, -0.0882,  0.0780,  0.1033,  0.0648, -0.0341,  0.0122, -0.0119,\n",
      "          0.0177,  0.0067,  0.0830,  0.0863,  0.0869,  0.0604,  0.0682,  0.0734,\n",
      "          0.0846,  0.0437, -0.0695,  0.0976,  0.0220, -0.0659, -0.0099,  0.0403,\n",
      "         -0.0889, -0.0849, -0.0445,  0.0882,  0.0410,  0.0559,  0.0465,  0.0951,\n",
      "          0.0974,  0.1018,  0.0684,  0.0532,  0.0421,  0.0886, -0.1047,  0.0518,\n",
      "          0.1065,  0.0381,  0.0025, -0.0355,  0.0278, -0.0517,  0.0392, -0.0233,\n",
      "          0.0412, -0.0689, -0.0730, -0.0889],\n",
      "        [ 0.0211,  0.0628,  0.0693, -0.0847,  0.0383,  0.0297,  0.0693, -0.0705,\n",
      "         -0.0365, -0.0748,  0.0076, -0.0852,  0.0821, -0.0947,  0.0081,  0.0159,\n",
      "         -0.0058, -0.0768,  0.0460,  0.0884,  0.0024,  0.0706, -0.0973, -0.0135,\n",
      "         -0.0169,  0.0932,  0.0269, -0.0902,  0.0224,  0.0129,  0.0112,  0.0595,\n",
      "          0.0545, -0.0263,  0.0419, -0.0140, -0.0723,  0.0820,  0.0403,  0.0803,\n",
      "         -0.0726,  0.0017, -0.0765, -0.0334,  0.0872, -0.0266,  0.0411,  0.0467,\n",
      "         -0.0758,  0.0754, -0.0838,  0.0873, -0.0258, -0.1054,  0.0052,  0.1044,\n",
      "          0.0385, -0.0294,  0.0247,  0.0435, -0.0972, -0.0924, -0.0883,  0.0991,\n",
      "         -0.0663, -0.0510,  0.0565, -0.0589,  0.0159,  0.0703,  0.0290,  0.0007,\n",
      "         -0.0742, -0.0620, -0.0272,  0.1014,  0.0284,  0.0358,  0.0107,  0.0040,\n",
      "          0.0957,  0.0221,  0.0344,  0.0343],\n",
      "        [ 0.0592,  0.1049, -0.0349, -0.0202,  0.0299,  0.0612,  0.1015, -0.0460,\n",
      "          0.0150,  0.0656,  0.0492,  0.0954,  0.0042, -0.0902,  0.0111, -0.0616,\n",
      "          0.0120, -0.0602, -0.0323, -0.0048, -0.0279, -0.0516,  0.0482, -0.0748,\n",
      "          0.0679, -0.0312,  0.0778, -0.0607,  0.0754,  0.0605,  0.0722, -0.1035,\n",
      "         -0.0362, -0.0975, -0.1060, -0.0828,  0.0828, -0.0497, -0.0539, -0.0125,\n",
      "          0.0375, -0.0029, -0.0727,  0.0555,  0.0570,  0.0795,  0.0531,  0.0637,\n",
      "          0.0572,  0.0589,  0.1058, -0.0806,  0.0813, -0.0870, -0.0609, -0.0027,\n",
      "          0.0824, -0.0554,  0.0745, -0.0768, -0.0549,  0.0557,  0.0213, -0.0224,\n",
      "         -0.0928,  0.0730, -0.0739,  0.0719,  0.0562, -0.0152, -0.0026, -0.1034,\n",
      "          0.0232,  0.0055, -0.0531, -0.0987,  0.0396,  0.0292,  0.0619, -0.0272,\n",
      "         -0.1031, -0.0822, -0.0343,  0.0954],\n",
      "        [ 0.0040, -0.0493,  0.0212,  0.0647,  0.0705, -0.0557,  0.0793, -0.0454,\n",
      "         -0.0629, -0.0621, -0.0586,  0.0254,  0.0817,  0.0240, -0.0413,  0.0237,\n",
      "          0.1013, -0.0606, -0.0019, -0.0351,  0.0570, -0.0371, -0.0011, -0.0276,\n",
      "         -0.1048, -0.0766, -0.0335, -0.0390, -0.0980,  0.0408, -0.0779, -0.0918,\n",
      "          0.0603, -0.0652,  0.0758,  0.0123, -0.0990,  0.1045, -0.0989, -0.1033,\n",
      "         -0.0964,  0.0613, -0.1038, -0.0192,  0.0830, -0.0264,  0.0930, -0.0911,\n",
      "          0.0578, -0.0445, -0.0826,  0.0561, -0.0509, -0.0954,  0.0651, -0.0931,\n",
      "         -0.0746, -0.0657,  0.0456,  0.0280, -0.0925, -0.1074, -0.0916,  0.0258,\n",
      "         -0.0556, -0.0061,  0.0757, -0.0800,  0.0007, -0.0619,  0.0133,  0.1062,\n",
      "         -0.0659,  0.0780,  0.0803,  0.0844,  0.0086,  0.0840,  0.0899, -0.0879,\n",
      "         -0.0358, -0.0232,  0.0621, -0.0447],\n",
      "        [ 0.0359,  0.0852,  0.1054,  0.0382,  0.0210, -0.0368,  0.0491, -0.0443,\n",
      "          0.0771, -0.0022, -0.0886,  0.0879, -0.0399,  0.0714, -0.0201,  0.1035,\n",
      "          0.1042,  0.0694, -0.0221,  0.0005, -0.0487,  0.0003,  0.0991,  0.0182,\n",
      "          0.0800, -0.0938,  0.0539, -0.0963,  0.0380, -0.1066, -0.0198, -0.0787,\n",
      "         -0.0558,  0.1086, -0.0277,  0.0586, -0.0358, -0.0492, -0.1051, -0.0162,\n",
      "          0.1058, -0.0468, -0.0245, -0.0906, -0.1037,  0.1050,  0.0538, -0.0845,\n",
      "          0.0806, -0.0374,  0.0376, -0.0050,  0.0191, -0.1032, -0.0361, -0.0882,\n",
      "          0.1031,  0.0382,  0.0413,  0.0600, -0.0701,  0.0848,  0.0677,  0.0486,\n",
      "          0.1051,  0.0244, -0.0405,  0.0713, -0.0040, -0.0774, -0.0025, -0.0208,\n",
      "         -0.0905, -0.0729,  0.0716, -0.0087,  0.0324, -0.0742, -0.0241,  0.0251,\n",
      "          0.1058, -0.0039,  0.0158, -0.1049],\n",
      "        [-0.0628, -0.0878,  0.0763,  0.0617,  0.0888, -0.0173,  0.0895,  0.0249,\n",
      "          0.0028,  0.0626,  0.0481,  0.0865,  0.0291, -0.0398,  0.0417,  0.0020,\n",
      "          0.0213,  0.0773,  0.0729, -0.0516,  0.0983,  0.0902, -0.0495,  0.0275,\n",
      "         -0.0764, -0.0047, -0.0669,  0.1046, -0.1020, -0.0022, -0.0765, -0.0040,\n",
      "         -0.1071, -0.0907,  0.0941, -0.0012,  0.0884, -0.0856, -0.0452,  0.1071,\n",
      "         -0.0486, -0.0602,  0.0889, -0.0834,  0.0450, -0.0998,  0.0317,  0.0055,\n",
      "         -0.1032,  0.0982, -0.0634, -0.0558,  0.1079, -0.0984, -0.0051,  0.0962,\n",
      "         -0.0767, -0.0544, -0.0041, -0.0942,  0.1025, -0.0020, -0.0915, -0.0235,\n",
      "         -0.0664,  0.0918,  0.0847,  0.0366, -0.0087,  0.1066,  0.0862,  0.0393,\n",
      "         -0.0934, -0.0306, -0.0805,  0.0355,  0.0673,  0.0745, -0.0246, -0.0379,\n",
      "          0.0593,  0.0546,  0.1086, -0.0660],\n",
      "        [ 0.1021, -0.0642,  0.0284, -0.0675, -0.1070,  0.0793,  0.0111,  0.0355,\n",
      "         -0.0357, -0.0184, -0.0397, -0.0551,  0.0942, -0.0625, -0.0048, -0.0386,\n",
      "         -0.1089,  0.0570,  0.1077, -0.0330, -0.0978,  0.0119, -0.0699, -0.0238,\n",
      "         -0.0631, -0.0103,  0.0035, -0.0923, -0.0942, -0.0357,  0.0766, -0.0189,\n",
      "         -0.0281, -0.0299, -0.0730, -0.0560, -0.0871, -0.1007,  0.0981, -0.0694,\n",
      "         -0.0293,  0.0322, -0.0315,  0.0487,  0.0935,  0.0130,  0.0965, -0.0375,\n",
      "         -0.0071, -0.0246,  0.0337, -0.0683,  0.1067,  0.0162, -0.0884,  0.1023,\n",
      "         -0.0524,  0.0434, -0.0031, -0.0372, -0.0488, -0.0936,  0.0193,  0.0174,\n",
      "          0.1028,  0.0344, -0.0675,  0.0182,  0.0852,  0.0666,  0.0953, -0.0364,\n",
      "          0.0892,  0.0258,  0.0221, -0.0710, -0.0403,  0.0120, -0.1073,  0.0456,\n",
      "         -0.0709, -0.0186, -0.0657,  0.0840],\n",
      "        [-0.0155,  0.0614,  0.0309,  0.0086, -0.0071,  0.0882, -0.0411,  0.0810,\n",
      "          0.1007, -0.0145, -0.0551,  0.0885, -0.0476,  0.0442, -0.0037, -0.0530,\n",
      "          0.0212,  0.0731, -0.0790, -0.0987, -0.0694, -0.0940, -0.1004,  0.0321,\n",
      "          0.0711, -0.1020,  0.0809,  0.0850, -0.0105, -0.0428,  0.0824,  0.0646,\n",
      "         -0.0827, -0.0709,  0.0913,  0.0088, -0.0296, -0.0325,  0.1031, -0.0141,\n",
      "          0.0949,  0.0054, -0.0139, -0.0252,  0.0315,  0.0637,  0.0267,  0.0253,\n",
      "         -0.0564, -0.0872, -0.0508,  0.0945,  0.0975,  0.0177,  0.0940, -0.0738,\n",
      "         -0.0525, -0.0044, -0.0806,  0.0858, -0.0377, -0.0672,  0.1069, -0.0107,\n",
      "         -0.0811,  0.0484, -0.0447, -0.0863, -0.0419,  0.0482, -0.0742,  0.0693,\n",
      "          0.0164, -0.0786,  0.0160, -0.0936,  0.0943, -0.1089, -0.0686,  0.0901,\n",
      "         -0.0554, -0.0398,  0.0504,  0.0972],\n",
      "        [ 0.0186, -0.0742,  0.0939, -0.0619,  0.0032, -0.0398,  0.0144,  0.0391,\n",
      "          0.0971, -0.1045,  0.0616, -0.0703, -0.0124,  0.0156,  0.1049, -0.1022,\n",
      "          0.0343, -0.1026,  0.0860,  0.0336, -0.0295, -0.0593,  0.0172,  0.0724,\n",
      "          0.0898,  0.0321, -0.0963, -0.0986, -0.0019,  0.0379, -0.0537,  0.0474,\n",
      "         -0.0339,  0.0696, -0.0688,  0.0789,  0.0768, -0.0309,  0.0261,  0.0124,\n",
      "         -0.0040, -0.0936, -0.0479, -0.0150, -0.0706, -0.0253, -0.1053,  0.0656,\n",
      "          0.0729,  0.0296,  0.0949, -0.0721,  0.0266, -0.0155, -0.0430,  0.0036,\n",
      "         -0.0411, -0.0384,  0.0130, -0.0367,  0.0120, -0.0739,  0.0287, -0.0913,\n",
      "          0.0911,  0.1081,  0.0193,  0.0790, -0.0005, -0.0344,  0.0530,  0.0209,\n",
      "          0.0620, -0.0369,  0.1019,  0.0579, -0.1069,  0.0029,  0.0717, -0.0314,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.0436,  0.0081, -0.0750, -0.0623]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0363, -0.1061,  0.0859,  0.0742, -0.0242, -0.0972,  0.0560, -0.0302,\n",
      "         0.0280, -0.0756], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "This time we'll feed the data directly into the model without flattening it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.21157134  accuracy:  78.233%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.61619765  accuracy:  85.392%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.02542202  accuracy:  88.494%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.02767749  accuracy:  90.283%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.00643819  accuracy:  91.450%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.00354728  accuracy:  92.267%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.06529951  accuracy:  92.869%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.00221968  accuracy:  93.412%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00033455  accuracy:  93.837%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.00892201  accuracy:  94.195%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.03726712  accuracy:  97.717%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.31302613  accuracy:  97.700%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.19266316  accuracy:  97.761%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00095279  accuracy:  97.875%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00099270  accuracy:  97.880%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.15359043  accuracy:  97.911%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.00465962  accuracy:  97.926%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.20287080  accuracy:  97.942%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.02403117  accuracy:  97.987%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.00562875  accuracy:  97.980%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00386984  accuracy:  98.717%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00092322  accuracy:  98.608%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00036388  accuracy:  98.511%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.00017684  accuracy:  98.471%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.03143325  accuracy:  98.493%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00005292  accuracy:  98.508%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00247721  accuracy:  98.488%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00065585  accuracy:  98.471%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00127100  accuracy:  98.507%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00011644  accuracy:  98.517%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.03062764  accuracy:  98.917%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.02100378  accuracy:  98.917%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.00514422  accuracy:  98.856%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.00140927  accuracy:  98.850%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.00011928  accuracy:  98.870%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.00079771  accuracy:  98.844%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00132713  accuracy:  98.843%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.00449947  accuracy:  98.873%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00113259  accuracy:  98.898%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00009867  accuracy:  98.860%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00142467  accuracy:  99.067%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.27139300  accuracy:  98.967%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00808769  accuracy:  98.983%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00000675  accuracy:  98.996%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.00410451  accuracy:  98.953%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.00055251  accuracy:  98.983%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00038263  accuracy:  98.979%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00008446  accuracy:  99.017%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.31358677  accuracy:  99.033%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00272598  accuracy:  99.028%\n",
      "\n",
      "Duration: 283 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0081),\n",
       " tensor(0.0014),\n",
       " tensor(0.0003),\n",
       " tensor(3.3747e-05),\n",
       " tensor(3.4521e-05)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may be some overfitting of the training data, there is far less than we saw with the ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(56517)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(  94, dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 100*train_correct[0]/(len(train_loader)*10)\n",
    "temp.numpy() # converts tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9860/10000 =  98.600%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our [784,120,84,10] ANN returned an accuracy of 97.25% after 10 epochs. And it used 105,214 parameters to our current 60,074."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 978    0    2    0    1    2    4    2   15    1]\n",
      " [   0 1132    6    0    0    0    4    3    0    0]\n",
      " [   0    0 1009    0    0    0    0    1    2    0]\n",
      " [   0    0    2 1009    0   15    0    0    5    2]\n",
      " [   0    0    1    0  965    0    3    0    0    2]\n",
      " [   0    0    0    1    0  869    4    0    2    3]\n",
      " [   1    1    0    0    1    1  942    0    0    0]\n",
      " [   1    1   11    0    1    1    0 1015    3    3]\n",
      " [   0    1    1    0    4    3    1    2  944    1]\n",
      " [   0    0    0    0   10    1    0    5    3  997]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 184,  266,  321,  340,  412,  445,  460,  497,  511,  543],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x2340bfc72b0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [ 184  266  321  340  412  445  460  497  511  543  582  659]\n",
      "Label: [   8    8    2    5    5    6    5    4    4    8    8    2]\n",
      "Guess: [   3    0    7    3    3    0    9    9    8    3    2    7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a new image through the model\n",
    "We can also pass a single image through the model to obtain a prediction.\n",
    "Pick a number from 0 to 9999, assign it to \"x\", and we'll use that value to select a number from the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 2019\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(test_data[x][0].reshape((28,28)), cmap=\"gist_yarg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())\n",
    "# model.eval() vs torch.no_grad()\n",
    "# https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
