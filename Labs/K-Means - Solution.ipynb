{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the scratch code of K-means clustering in our lecture:\n",
    "- Modify so it print out the total within-cluster variation.  Then try to run several k and identify which k is best.\n",
    "- Since k-means can be slow due to its pairwise computations, let's implement a mini-batch k-means in which the cluster is create using only partial subset of samples.\n",
    "- Put everything into a class\n",
    "\n",
    "Mini-Batch will rarely converge, thus it is important to add a max_iteration or some tolerance.  Last, theoretically speaking, Mini-Batch will never perform better in terms of accuracy when compare to K-means, but it is very close to optimal but will almost always beat K-means in terms of time given large dataset and a modest tolerance parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====k = 2\n",
      "Done in 6 iterations\n",
      "Total with variation score:  5859.027548790498\n",
      "Fit and predict time 0.007968902587890625\n",
      "=====k = 3\n",
      "Done in 3 iterations\n",
      "Total with variation score:  2849.7266714358066\n",
      "Fit and predict time 0.00592803955078125\n",
      "=====k = 4\n",
      "Done in 9 iterations\n",
      "Total with variation score:  1007.7374341654453\n",
      "Fit and predict time 0.008007287979125977\n",
      "=====k = 5\n",
      "Done in 9 iterations\n",
      "Total with variation score:  920.8127407429872\n",
      "Fit and predict time 0.010268211364746094\n",
      "=====k = 6\n",
      "Done in 3 iterations\n",
      "Total with variation score:  841.4034939553978\n",
      "Fit and predict time 0.00701904296875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import make_blobs\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "X, y_true = make_blobs(n_samples=1500, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "class Mini_KMeans:\n",
    "    def __init__(self, k, replacement=True, batch_size=100, max_iter=100):\n",
    "        self.k = k\n",
    "        self.replacement=replacement\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def fit(self, X):\n",
    "        m, n = X.shape\n",
    "\n",
    "        #1. randomly choose k clusters from X\n",
    "        rng = np.random.RandomState(99)\n",
    "        i = rng.permutation(m)[:self.k]\n",
    "        self.centers = X[i]\n",
    "\n",
    "        #having max iter makes sure it will stop eventually\n",
    "        for ix in np.arange(self.max_iter):\n",
    "            random = rng.randint(m)\n",
    "            X_batch = X[random:random+self.batch_size]\n",
    "\n",
    "            #2. assign labels based on closest center\n",
    "            labels = pairwise_distances_argmin(X_batch, self.centers)\n",
    "\n",
    "            #3. find new centers\n",
    "            new_centers = []\n",
    "            for i in range(self.k):\n",
    "                new_centers.append(X_batch[labels == i].mean(axis=0))\n",
    "\n",
    "            #convert list to np.array; you can actually combine #3\n",
    "            #with np.array in one sentence \n",
    "            new_centers = np.array(new_centers)\n",
    "\n",
    "            #4 stopping criteria - if centers do not \n",
    "            #change anymore, we stop!\n",
    "            #make sure to add rtol or atol since mini-batch does not converge\n",
    "            if(np.allclose(self.centers, new_centers, rtol=0.2)):\n",
    "                break\n",
    "            else:\n",
    "                self.centers = new_centers\n",
    "\n",
    "        print(f\"Done in {ix} iterations\")\n",
    "\n",
    "        #compute total within-variation score\n",
    "        total_with_variation_score = 0\n",
    "        labels = pairwise_distances_argmin(X, self.centers) #<---Note I use X here.  Why?\n",
    "        for i in range(self.k):\n",
    "            cluster_mean = X[labels==i].mean(axis=0)\n",
    "            total_with_variation_score += ((X[labels==i] - cluster_mean)** 2).sum()\n",
    "            \n",
    "        print(\"Total with variation score: \", total_with_variation_score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return pairwise_distances_argmin(X, self.centers)\n",
    "\n",
    "#main code\n",
    "\n",
    "for k in range(2, 7):\n",
    "    print(f\"=====k = {k}\")\n",
    "    start = time()\n",
    "    model = Mini_KMeans(k)\n",
    "    model.fit(X)\n",
    "    preds = model.predict(X)\n",
    "    print(f\"Fit and predict time {time() - start}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
